name: Build updates.json (Python, multi-source, robust)

on:
  schedule:
    - cron: "17 13 * * *"   # daily ~9:17am ET
  workflow_dispatch: {}      # run by hand

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Build updates.json via Python
        run: |
          python - << 'PY'
          import json, re, ssl, sys, time, urllib.request

          UA = "hr-law-updates/1.0 (+github actions)"

          def fetch_text(url, accept="*/*", timeout=40):
            try:
              ctx = ssl.create_default_context()
              req = urllib.request.Request(url, headers={"accept": accept, "user-agent": UA})
              with urllib.request.urlopen(req, context=ctx, timeout=timeout) as r:
                raw = r.read().decode("utf-8", errors="replace")
              print(f"[fetch_text] {url} -> {len(raw)} bytes")
              return raw
            except Exception as e:
              print(f"[fetch_text] ERROR {url}: {e}", file=sys.stderr)
              return ""

          def fetch_json(url):
            try:
              raw = fetch_text(url, accept="application/json")
              return json.loads(raw)
            except Exception as e:
              print(f"[fetch_json] ERROR {url}: {e}", file=sys.stderr)
              return []

          def item(id, source, title, date, url, tags=None):
            return {
              "id": id, "source": source, "title": title.strip()[:300],
              "date": date, "url": url, "tags": (tags or [])
            }

          # ---------- Source A: NYC Council (Legistar API) ----------
          def pull_nyc_council():
            url = "https://webapi.legistar.com/v1/nyc/Matters?$orderby=LastModifiedUtc%20desc&$top=50"
            data = fetch_json(url)
            out = []
            now = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
            if isinstance(data, list):
              for m in data:
                mid   = m.get("MatterId")
                title = m.get("MatterTitle") or m.get("MatterName") or m.get("MatterFile") or "NYC Council matter"
                date  = m.get("LastModifiedUtc") or m.get("MatterIntroDate") or now
                link  = m.get("MatterHyperlink") or f"https://legistar.council.nyc.gov/LegislationDetail.aspx?ID={mid}"
                out.append(item(f"nycc-{mid}", "NYC Council", title, date, link, ["NYC"]))
            print(f"[NYC Council] {len(out)} items")
            return out

          # ---------- Source B: NYC Rules (simple text scrape) ----------
          def pull_nyc_rules():
            html = fetch_text("https://rules.cityofnewyork.us/")
            text = re.sub(r"<[^>]+>", " ", html)          # strip tags
            text = re.sub(r"\s+", " ", text).strip()
            chunks = re.split(r"(Proposed Rule|Adopted Rule|Notice of Public Hearing)", text)
            out = []
            now = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
            # pair section headers with following text
            for i in range(1, min(len(chunks), 30), 2):
              head = chunks[i]
              body = chunks[i+1] if i+1 < len(chunks) else ""
              title = f"{head}: {body[:120]}…"
              out.append(item(f"nycr-{i}-{int(time.time())}", "NYC Rules", title, now, "https://rules.cityofnewyork.us/", ["NYC","Rules"]))
            print(f"[NYC Rules] {len(out)} items")
            return out

          # ---------- Source C: NYS Register (landing page scrape) ----------
          def pull_nys_register():
            html = fetch_text("https://dos.ny.gov/state-register")
            text = re.sub(r"<[^>]+>", " ", html)
            lines = [x.strip() for x in re.split(r"[\\n\\.]", text) if x.strip()]
            out = []
            now = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
            for line in lines:
              if re.search(r"(labor|employment|wage|salary|sick|leave|retaliation|schedule|minimum wage)", line, re.I):
                out.append(item(f"nysr-{len(out)}-{int(time.time())}", "NYS Register", line[:140]+"…", now, "https://dos.ny.gov/state-register", ["NYS","Rulemaking"]))
                if len(out) >= 10: break
            print(f"[NYS Register] {len(out)} items")
            return out

          # ---------- Aggregate ----------
          all_items = []
          try:   all_items += pull_nyc_council()
          except Exception as e: print("[agg] NYC Council failed:", e, file=sys.stderr)
          try:   all_items += pull_nyc_rules()
          except Exception as e: print("[agg] NYC Rules failed:", e, file=sys.stderr)
          try:   all_items += pull_nys_register()
          except Exception as e: print("[agg] NYS Register failed:", e, file=sys.stderr)

          # De-dup by (source,title)
          seen = set()
          out = []
          for it in all_items:
            key = (it["source"], it["title"])
            if key in seen: continue
            seen.add(key); out.append(it)

          # If everything failed, keep 2 examples so the site shows something
          if not out:
            now = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
            out = [
              item("ex1","NYC Council","(Example) Amend Safe and Sick Time Act","2025-09-20","https://council.nyc.gov/legislation/",["NYC","Leave"]),
              item("ex2","NYC Rules","(Example) Proposed payroll record rule","2025-09-18","https://rules.cityofnewyork.us/",["NYC","Records"]),
            ]
            print("[agg] No live items; wrote examples.")

          # Sort newest first if dates parse, otherwise leave as-is
          try:
            out.sort(key=lambda x: x.get("date",""), reverse=True)
          except Exception:
            pass

          with open("updates.json","w",encoding="utf-8") as f:
            json.dump(out, f, indent=2)
          print(f"[write] updates.json with {len(out)} items")
          PY

      - name: Commit updates.json if changed
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add updates.json
            git commit -m "chore: update updates.json (python robust multi-source)"
            git push
          else
            echo "No changes to commit."
          fi
